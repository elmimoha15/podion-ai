import os
import logging
from datetime import datetime
from typing import Optional, Dict, Any, List
import firebase_admin
from firebase_admin import firestore
from fastapi import HTTPException
import uuid

logger = logging.getLogger(__name__)

def get_firestore_client():
    """Get Firestore client instance"""
    try:
        # Firebase Admin SDK should already be initialized
        if not firebase_admin._apps:
            raise ValueError("Firebase Admin SDK not initialized")
        
        db = firestore.client()
        return db
    except Exception as e:
        logger.error(f"Failed to get Firestore client: {e}")
        raise HTTPException(status_code=500, detail="Firestore database not available")

def generate_podcast_doc_id() -> str:
    """Generate unique document ID for podcast"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    unique_id = str(uuid.uuid4())[:8]
    return f"podcast_{timestamp}_{unique_id}"

def save_podcast_metadata(
    user_id: str,
    filename: str,
    audio_url: str,
    transcript: str,
    deepgram_words: List[Dict[str, Any]],
    gemini_seo_content: Dict[str, Any],
    storage_path: Optional[str] = None,
    file_size: Optional[int] = None,
    processing_metadata: Optional[Dict[str, Any]] = None,
    workspace_id: Optional[str] = None
) -> str:
    """
    Save complete podcast metadata to Firestore
    
    Args:
        user_id: User ID who owns the podcast
        filename: Original filename
        audio_url: Public URL to audio file
        transcript: Full transcript text
        deepgram_words: Word-level timestamps from Deepgram
        gemini_seo_content: All SEO content generated by Gemini
        storage_path: Firebase Storage path (optional)
        file_size: File size in bytes (optional)
        processing_metadata: Additional processing info (optional)
    
    Returns:
        Document ID of saved podcast
    """
    
    try:
        db = get_firestore_client()
        
        # Generate unique document ID
        doc_id = generate_podcast_doc_id()
        
        # Prepare podcast document
        podcast_doc = {
            "user_id": user_id,
            "workspace_id": workspace_id,
            "filename": filename,
            "audio_url": audio_url,
            "storage_path": storage_path,
            "file_size": file_size,
            "transcript": {
                "full_text": transcript,
                "word_count": len(transcript.split()) if transcript else 0,
                "source": "deepgram_nova2"
            },
            "deepgram_data": {
                "words": deepgram_words,
                "word_count": len(deepgram_words),
                "speakers_detected": len(set(w.get("speaker") for w in deepgram_words if w.get("speaker") is not None)),
                "model": "nova-2",
                "features": ["word_timestamps", "speaker_diarization", "smart_format", "punctuation"]
            },
            "seo_content": gemini_seo_content,
            "metadata": {
                "created_at": firestore.SERVER_TIMESTAMP,
                "updated_at": firestore.SERVER_TIMESTAMP,
                "version": "1.0",
                "processing_status": "completed"
            }
        }
        
        # Add processing metadata if provided
        if processing_metadata:
            podcast_doc["processing_info"] = processing_metadata
        
        # Save to Firestore
        doc_ref = db.collection("podcasts").document(doc_id)
        doc_ref.set(podcast_doc)
        
        logger.info(f"Saved podcast metadata to Firestore: {doc_id}")
        logger.info(f"User: {user_id}, Filename: {filename}")
        
        return doc_id
        
    except Exception as e:
        logger.error(f"Failed to save podcast metadata: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to save podcast metadata: {str(e)}"
        )

def get_podcast_metadata(doc_id: str) -> Dict[str, Any]:
    """
    Retrieve podcast metadata by document ID
    
    Args:
        doc_id: Document ID of the podcast
    
    Returns:
        Podcast metadata dictionary
    """
    
    try:
        db = get_firestore_client()
        
        doc_ref = db.collection("podcasts").document(doc_id)
        doc = doc_ref.get()
        
        if not doc.exists:
            raise HTTPException(status_code=404, detail="Podcast not found")
        
        podcast_data = doc.to_dict()
        podcast_data["doc_id"] = doc_id
        
        return podcast_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get podcast metadata: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to retrieve podcast metadata: {str(e)}"
        )

def list_user_podcasts(user_id: str, limit: int = 50) -> List[Dict[str, Any]]:
    """
    List all podcasts for a specific user
    
    Args:
        user_id: User ID to get podcasts for
        limit: Maximum number of podcasts to return
    
    Returns:
        List of podcast metadata dictionaries
    """
    
    try:
        db = get_firestore_client()
        
        # Query podcasts for user, ordered by creation date (newest first)
        query = db.collection("podcasts") \
                  .where("user_id", "==", user_id) \
                  .order_by("metadata.created_at", direction=firestore.Query.DESCENDING) \
                  .limit(limit)
        
        docs = query.stream()
        
        podcasts = []
        for doc in docs:
            podcast_data = doc.to_dict()
            podcast_data["doc_id"] = doc.id
            podcasts.append(podcast_data)
        
        logger.info(f"Retrieved {len(podcasts)} podcasts for user {user_id}")
        
        return podcasts
        
    except Exception as e:
        logger.error(f"Failed to list user podcasts: {str(e)}")
        return []

def update_podcast_metadata(doc_id: str, updates: Dict[str, Any]) -> bool:
    """
    Update specific fields in podcast metadata
    
    Args:
        doc_id: Document ID of the podcast
        updates: Dictionary of fields to update
    
    Returns:
        True if updated successfully
    """
    
    try:
        db = get_firestore_client()
        
        # Add updated timestamp
        updates["metadata.updated_at"] = firestore.SERVER_TIMESTAMP
        
        doc_ref = db.collection("podcasts").document(doc_id)
        doc_ref.update(updates)
        
        logger.info(f"Updated podcast metadata: {doc_id}")
        
        return True
        
    except Exception as e:
        logger.error(f"Failed to update podcast metadata: {str(e)}")
        return False

def delete_podcast_metadata(doc_id: str) -> bool:
    """
    Delete podcast metadata from Firestore
    
    Args:
        doc_id: Document ID of the podcast
    
    Returns:
        True if deleted successfully
    """
    
    try:
        db = get_firestore_client()
        
        doc_ref = db.collection("podcasts").document(doc_id)
        doc_ref.delete()
        
        logger.info(f"Deleted podcast metadata: {doc_id}")
        
        return True
        
    except Exception as e:
        logger.error(f"Failed to delete podcast metadata: {str(e)}")
        return False

def search_podcasts_by_title(user_id: str, title_query: str, limit: int = 20) -> List[Dict[str, Any]]:
    """
    Search podcasts by title/filename for a specific user
    
    Args:
        user_id: User ID to search within
        title_query: Search query for filename
        limit: Maximum results to return
    
    Returns:
        List of matching podcast metadata
    """
    
    try:
        db = get_firestore_client()
        
        # Note: Firestore doesn't support full-text search natively
        # This is a simple contains search on filename
        query = db.collection("podcasts") \
                  .where("user_id", "==", user_id) \
                  .where("filename", ">=", title_query) \
                  .where("filename", "<=", title_query + "\uf8ff") \
                  .limit(limit)
        
        docs = query.stream()
        
        podcasts = []
        for doc in docs:
            podcast_data = doc.to_dict()
            podcast_data["doc_id"] = doc.id
            podcasts.append(podcast_data)
        
        return podcasts
        
    except Exception as e:
        logger.error(f"Failed to search podcasts: {str(e)}")
        return []

def get_podcast_stats(user_id: str) -> Dict[str, Any]:
    """
    Get statistics about user's podcasts
    
    Args:
        user_id: User ID to get stats for
    
    Returns:
        Dictionary with podcast statistics
    """
    
    try:
        db = get_firestore_client()
        
        # Get all podcasts for user
        query = db.collection("podcasts").where("user_id", "==", user_id)
        docs = list(query.stream())
        
        if not docs:
            return {
                "total_podcasts": 0,
                "total_storage_mb": 0,
                "total_transcript_words": 0,
                "avg_speakers_per_episode": 0,
                "latest_podcast": None
            }
        
        total_storage = 0
        total_words = 0
        total_speakers = 0
        latest_date = None
        
        for doc in docs:
            data = doc.to_dict()
            
            # Storage
            if data.get("file_size"):
                total_storage += data["file_size"]
            
            # Words
            if data.get("transcript", {}).get("word_count"):
                total_words += data["transcript"]["word_count"]
            
            # Speakers
            if data.get("deepgram_data", {}).get("speakers_detected"):
                total_speakers += data["deepgram_data"]["speakers_detected"]
            
            # Latest date
            created_at = data.get("metadata", {}).get("created_at")
            if created_at and (not latest_date or created_at > latest_date):
                latest_date = created_at
        
        return {
            "total_podcasts": len(docs),
            "total_storage_mb": round(total_storage / (1024 * 1024), 2),
            "total_transcript_words": total_words,
            "avg_speakers_per_episode": round(total_speakers / len(docs), 1) if docs else 0,
            "latest_podcast": latest_date.isoformat() if latest_date else None
        }
        
    except Exception as e:
        logger.error(f"Failed to get podcast stats: {str(e)}")
        return {}

def save_complete_podcast_workflow(
    user_id: str,
    filename: str,
    audio_url: str,
    storage_path: str,
    file_size: int,
    transcript_response: Dict[str, Any],
    seo_response: Dict[str, Any],
    workspace_id: Optional[str] = None
) -> str:
    """
    Convenience function to save complete podcast workflow results
    
    Args:
        user_id: User ID
        filename: Original filename
        audio_url: Public audio URL
        storage_path: Firebase Storage path
        file_size: File size in bytes
        transcript_response: Complete response from transcription service
        seo_response: Complete response from SEO generation service
    
    Returns:
        Document ID of saved podcast
    """
    
    try:
        # Extract transcript and words from transcription response
        transcript = transcript_response.get("transcript", "")
        words = transcript_response.get("words", [])
        
        # Convert word objects to dictionaries for Firestore
        deepgram_words = []
        if words:
            for word in words:
                if hasattr(word, 'dict'):
                    deepgram_words.append(word.dict())
                elif isinstance(word, dict):
                    deepgram_words.append(word)
                else:
                    # Handle other formats
                    deepgram_words.append({
                        "word": getattr(word, 'word', ''),
                        "start": getattr(word, 'start', 0.0),
                        "end": getattr(word, 'end', 0.0),
                        "confidence": getattr(word, 'confidence', 0.0),
                        "speaker": getattr(word, 'speaker', None)
                    })
        
        # Extract SEO content
        seo_content = {
            "seo_title": seo_response.get("seo_title", ""),
            "show_notes": seo_response.get("show_notes", []),
            "blog_post": seo_response.get("blog_post", {}),
            "social_media": seo_response.get("social_media", {}),
            "generation_metadata": seo_response.get("metadata", {})
        }
        
        # Processing metadata
        processing_metadata = {
            "transcription_metadata": transcript_response.get("metadata", {}),
            "seo_generation_metadata": seo_response.get("metadata", {}),
            "workflow_completed_at": datetime.now().isoformat(),
            "services_used": ["deepgram", "gemini", "firebase_storage", "firebase_firestore"]
        }
        
        # Extract upload_id from transcription metadata if available
        transcription_metadata = transcript_response.get("metadata", {})
        if "upload_id" in transcription_metadata:
            processing_metadata["upload_id"] = transcription_metadata["upload_id"]
        
        # Save to Firestore
        doc_id = save_podcast_metadata(
            user_id=user_id,
            filename=filename,
            audio_url=audio_url,
            transcript=transcript,
            deepgram_words=deepgram_words,
            gemini_seo_content=seo_content,
            storage_path=storage_path,
            file_size=file_size,
            processing_metadata=processing_metadata,
            workspace_id=workspace_id
        )
        
        logger.info(f"Complete podcast workflow saved: {doc_id}")
        
        return doc_id
        
    except Exception as e:
        logger.error(f"Failed to save complete podcast workflow: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to save podcast workflow: {str(e)}"
        ) 